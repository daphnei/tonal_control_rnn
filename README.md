# Recurrent Neural Nets for Music Generation

## Goals
Our goal is to design an architecutre for generating a music sequence gven another sequence correspnding in time. For example, generating a melody track given a drum beat, or generating the righthand of a piano, given the left hand. At training time, the network will be provided with two sequences which match temporally. We will refer to these as the melody and harmony sequences. At test time, only the harmony sequence will be provided, and a melody sequence will be generated by the network.

## Resources 

#####[RNN RBM] (https://github.com/tensorflow/magenta/blob/master/magenta/reviews/rnnrbm.md)
This blog post describes how to do polyphonic music generations using RBMs whose input is provided at each step by the RNN. Perhaps, we will incorporate RBMs once we have a basic architecute working. The sample code for the blog post also contains some convenient code for reading MIDI into vectors, which me might borrow. 

#####[Recurrent Neural Network (RNN) basics and the Long Short Term Memory (LSTM)](https://pythonprogramming.net/recurrent-neural-network-rnn-lstm-machine-learning-tutorial/)
Learn about RNN & LSTM basics in python

#####[The Unreasonable Effectiveness of Recurrent Neural Networks by Andrej Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
Good resource for learning about RNN's

#####[Understanding LSTM Networks by colah's blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
Suggested by Benedict

#####[Wavenet: A generative model for raw audio/Deepmind](https://deepmind.com/blog/wavenet-generative-model-raw-audio/)

Explains idea of dilated multilayer RNN's

## To Do List
  1. Add MIDI to vector code
  2. data processing pipeline - ensure propagation melody_input time t+1 to all nodes
  3. Implement basic 1 layer LSTM network 
  4. design a cost function - use L2 norm to start
  5. 
  








